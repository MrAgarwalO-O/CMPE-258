{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itQf8OnkWn0U",
        "outputId": "bb691a37-489a-488b-8a20-92165852502b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-cv\n",
            "  Downloading keras_cv-0.8.2-py3-none-any.whl (613 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-cv) (24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-cv) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras-cv) (4.9.4)\n",
            "Collecting keras-core (from keras-cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-cv) (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-cv) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (13.7.1)\n",
            "Collecting namex (from keras-core->keras-cv)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (6.3.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (4.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-cv) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras-cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-cv) (2.16.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv) (1.63.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv) (0.1.2)\n",
            "Installing collected packages: namex, keras-core, keras-cv\n",
            "Successfully installed keras-core-0.1.7 keras-cv-0.8.2 namex-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/pothole.zip -d /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56PxoEvYWxoT",
        "outputId": "e0f9ee4e-ae6d-41a1-bd4e-50e1a08abb51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/pothole.zip\n",
            "  inflating: /content/dataset/normal/1.jpg  \n",
            "  inflating: /content/dataset/normal/10.jpg  \n",
            "  inflating: /content/dataset/normal/100.jpg  \n",
            "  inflating: /content/dataset/normal/101.jpg  \n",
            "  inflating: /content/dataset/normal/102.jpg  \n",
            "  inflating: /content/dataset/normal/103.jpg  \n",
            "  inflating: /content/dataset/normal/104.jpg  \n",
            "  inflating: /content/dataset/normal/105.jpg  \n",
            "  inflating: /content/dataset/normal/106.jpg  \n",
            "  inflating: /content/dataset/normal/107.jpg  \n",
            "  inflating: /content/dataset/normal/108.jpg  \n",
            "  inflating: /content/dataset/normal/109.jpg  \n",
            "  inflating: /content/dataset/normal/11.jpg  \n",
            "  inflating: /content/dataset/normal/110.jpg  \n",
            "  inflating: /content/dataset/normal/111.jpg  \n",
            "  inflating: /content/dataset/normal/112.jpg  \n",
            "  inflating: /content/dataset/normal/113.jpg  \n",
            "  inflating: /content/dataset/normal/114.jpg  \n",
            "  inflating: /content/dataset/normal/115.jpg  \n",
            "  inflating: /content/dataset/normal/116.jpg  \n",
            "  inflating: /content/dataset/normal/117.jpg  \n",
            "  inflating: /content/dataset/normal/118.jpg  \n",
            "  inflating: /content/dataset/normal/119.jpg  \n",
            "  inflating: /content/dataset/normal/12.jpg  \n",
            "  inflating: /content/dataset/normal/120.jpg  \n",
            "  inflating: /content/dataset/normal/121.jpg  \n",
            "  inflating: /content/dataset/normal/122.jpg  \n",
            "  inflating: /content/dataset/normal/123.jpg  \n",
            "  inflating: /content/dataset/normal/124.jpg  \n",
            "  inflating: /content/dataset/normal/125.jpg  \n",
            "  inflating: /content/dataset/normal/126.jpg  \n",
            "  inflating: /content/dataset/normal/127.jpg  \n",
            "  inflating: /content/dataset/normal/128.jpg  \n",
            "  inflating: /content/dataset/normal/129.jpg  \n",
            "  inflating: /content/dataset/normal/13.jpg  \n",
            "  inflating: /content/dataset/normal/130.jpg  \n",
            "  inflating: /content/dataset/normal/131.jpg  \n",
            "  inflating: /content/dataset/normal/132.jpg  \n",
            "  inflating: /content/dataset/normal/133.jpg  \n",
            "  inflating: /content/dataset/normal/134.jpg  \n",
            "  inflating: /content/dataset/normal/135.jpg  \n",
            "  inflating: /content/dataset/normal/136.jpg  \n",
            "  inflating: /content/dataset/normal/137.jpg  \n",
            "  inflating: /content/dataset/normal/138.jpg  \n",
            "  inflating: /content/dataset/normal/139.jpg  \n",
            "  inflating: /content/dataset/normal/14.jpg  \n",
            "  inflating: /content/dataset/normal/140.jpg  \n",
            "  inflating: /content/dataset/normal/141.jpg  \n",
            "  inflating: /content/dataset/normal/142.jpg  \n",
            "  inflating: /content/dataset/normal/143.jpg  \n",
            "  inflating: /content/dataset/normal/144.jpg  \n",
            "  inflating: /content/dataset/normal/145.jpg  \n",
            "  inflating: /content/dataset/normal/146.jpg  \n",
            "  inflating: /content/dataset/normal/147.jpg  \n",
            "  inflating: /content/dataset/normal/148.jpg  \n",
            "  inflating: /content/dataset/normal/149.jpg  \n",
            "  inflating: /content/dataset/normal/15.jpg  \n",
            "  inflating: /content/dataset/normal/150.jpg  \n",
            "  inflating: /content/dataset/normal/151.jpg  \n",
            "  inflating: /content/dataset/normal/152.jpg  \n",
            "  inflating: /content/dataset/normal/153.jpg  \n",
            "  inflating: /content/dataset/normal/154.jpg  \n",
            "  inflating: /content/dataset/normal/155.jpg  \n",
            "  inflating: /content/dataset/normal/156.jpg  \n",
            "  inflating: /content/dataset/normal/157.jpg  \n",
            "  inflating: /content/dataset/normal/158.jpg  \n",
            "  inflating: /content/dataset/normal/159.jpg  \n",
            "  inflating: /content/dataset/normal/16.jpg  \n",
            "  inflating: /content/dataset/normal/160.jpg  \n",
            "  inflating: /content/dataset/normal/161.jpg  \n",
            "  inflating: /content/dataset/normal/162.jpg  \n",
            "  inflating: /content/dataset/normal/163.jpg  \n",
            "  inflating: /content/dataset/normal/164.jpg  \n",
            "  inflating: /content/dataset/normal/165.jpg  \n",
            "  inflating: /content/dataset/normal/166.jpg  \n",
            "  inflating: /content/dataset/normal/167.jpg  \n",
            "  inflating: /content/dataset/normal/168.jpg  \n",
            "  inflating: /content/dataset/normal/169.jpg  \n",
            "  inflating: /content/dataset/normal/17.jpg  \n",
            "  inflating: /content/dataset/normal/170.jpg  \n",
            "  inflating: /content/dataset/normal/171.jpg  \n",
            "  inflating: /content/dataset/normal/172.jpg  \n",
            "  inflating: /content/dataset/normal/173.jpg  \n",
            "  inflating: /content/dataset/normal/174.jpg  \n",
            "  inflating: /content/dataset/normal/175.jpg  \n",
            "  inflating: /content/dataset/normal/176.jpg  \n",
            "  inflating: /content/dataset/normal/177.jpg  \n",
            "  inflating: /content/dataset/normal/178.jpg  \n",
            "  inflating: /content/dataset/normal/179.jpg  \n",
            "  inflating: /content/dataset/normal/18.jpg  \n",
            "  inflating: /content/dataset/normal/180.jpg  \n",
            "  inflating: /content/dataset/normal/181.jpg  \n",
            "  inflating: /content/dataset/normal/182.jpg  \n",
            "  inflating: /content/dataset/normal/183.jpg  \n",
            "  inflating: /content/dataset/normal/184.jpg  \n",
            "  inflating: /content/dataset/normal/185.jpg  \n",
            "  inflating: /content/dataset/normal/186.jpg  \n",
            "  inflating: /content/dataset/normal/187.jpg  \n",
            "  inflating: /content/dataset/normal/188.jpg  \n",
            "  inflating: /content/dataset/normal/189.jpg  \n",
            "  inflating: /content/dataset/normal/19.jpg  \n",
            "  inflating: /content/dataset/normal/190.jpg  \n",
            "  inflating: /content/dataset/normal/191.jpg  \n",
            "  inflating: /content/dataset/normal/192.jpg  \n",
            "  inflating: /content/dataset/normal/193.jpg  \n",
            "  inflating: /content/dataset/normal/194.jpg  \n",
            "  inflating: /content/dataset/normal/195.jpg  \n",
            "  inflating: /content/dataset/normal/196.jpg  \n",
            "  inflating: /content/dataset/normal/197.jpg  \n",
            "  inflating: /content/dataset/normal/198.jpg  \n",
            "  inflating: /content/dataset/normal/199.jpg  \n",
            "  inflating: /content/dataset/normal/2.jpg  \n",
            "  inflating: /content/dataset/normal/20.jpg  \n",
            "  inflating: /content/dataset/normal/200.jpg  \n",
            "  inflating: /content/dataset/normal/201.jpg  \n",
            "  inflating: /content/dataset/normal/202.jpg  \n",
            "  inflating: /content/dataset/normal/203.jpg  \n",
            "  inflating: /content/dataset/normal/204.jpg  \n",
            "  inflating: /content/dataset/normal/205.jpg  \n",
            "  inflating: /content/dataset/normal/206.jpg  \n",
            "  inflating: /content/dataset/normal/207.jpg  \n",
            "  inflating: /content/dataset/normal/208.jpg  \n",
            "  inflating: /content/dataset/normal/209.jpg  \n",
            "  inflating: /content/dataset/normal/21.jpg  \n",
            "  inflating: /content/dataset/normal/210.jpg  \n",
            "  inflating: /content/dataset/normal/211.jpg  \n",
            "  inflating: /content/dataset/normal/212.jpg  \n",
            "  inflating: /content/dataset/normal/213.jpg  \n",
            "  inflating: /content/dataset/normal/214.jpg  \n",
            "  inflating: /content/dataset/normal/215.jpg  \n",
            "  inflating: /content/dataset/normal/216.jpg  \n",
            "  inflating: /content/dataset/normal/217.jpg  \n",
            "  inflating: /content/dataset/normal/218.jpg  \n",
            "  inflating: /content/dataset/normal/219.jpg  \n",
            "  inflating: /content/dataset/normal/22.jpg  \n",
            "  inflating: /content/dataset/normal/220.jpg  \n",
            "  inflating: /content/dataset/normal/221.jpg  \n",
            "  inflating: /content/dataset/normal/222.jpg  \n",
            "  inflating: /content/dataset/normal/223.jpg  \n",
            "  inflating: /content/dataset/normal/224.jpg  \n",
            "  inflating: /content/dataset/normal/225.jpg  \n",
            "  inflating: /content/dataset/normal/226.jpg  \n",
            "  inflating: /content/dataset/normal/227.jpg  \n",
            "  inflating: /content/dataset/normal/228.jpg  \n",
            "  inflating: /content/dataset/normal/229.jpg  \n",
            "  inflating: /content/dataset/normal/23.jpg  \n",
            "  inflating: /content/dataset/normal/230.jpg  \n",
            "  inflating: /content/dataset/normal/231.jpg  \n",
            "  inflating: /content/dataset/normal/232.jpg  \n",
            "  inflating: /content/dataset/normal/233.jpg  \n",
            "  inflating: /content/dataset/normal/234.jpg  \n",
            "  inflating: /content/dataset/normal/235.jpg  \n",
            "  inflating: /content/dataset/normal/236.jpg  \n",
            "  inflating: /content/dataset/normal/237.jpg  \n",
            "  inflating: /content/dataset/normal/238.jpg  \n",
            "  inflating: /content/dataset/normal/239.jpg  \n",
            "  inflating: /content/dataset/normal/24.jpg  \n",
            "  inflating: /content/dataset/normal/240.jpg  \n",
            "  inflating: /content/dataset/normal/241.jpg  \n",
            "  inflating: /content/dataset/normal/242.jpg  \n",
            "  inflating: /content/dataset/normal/243.jpg  \n",
            "  inflating: /content/dataset/normal/244.jpg  \n",
            "  inflating: /content/dataset/normal/245.jpg  \n",
            "  inflating: /content/dataset/normal/246.jpg  \n",
            "  inflating: /content/dataset/normal/247.jpg  \n",
            "  inflating: /content/dataset/normal/248.jpg  \n",
            "  inflating: /content/dataset/normal/249.jpg  \n",
            "  inflating: /content/dataset/normal/25.jpg  \n",
            "  inflating: /content/dataset/normal/250.jpg  \n",
            "  inflating: /content/dataset/normal/251.jpg  \n",
            "  inflating: /content/dataset/normal/252.jpg  \n",
            "  inflating: /content/dataset/normal/253.jpg  \n",
            "  inflating: /content/dataset/normal/254.jpg  \n",
            "  inflating: /content/dataset/normal/255.jpg  \n",
            "  inflating: /content/dataset/normal/256.jpg  \n",
            "  inflating: /content/dataset/normal/257.jpg  \n",
            "  inflating: /content/dataset/normal/258.jpg  \n",
            "  inflating: /content/dataset/normal/259.jpg  \n",
            "  inflating: /content/dataset/normal/26.jpg  \n",
            "  inflating: /content/dataset/normal/260.jpg  \n",
            "  inflating: /content/dataset/normal/261.jpg  \n",
            "  inflating: /content/dataset/normal/262.jpg  \n",
            "  inflating: /content/dataset/normal/263.jpg  \n",
            "  inflating: /content/dataset/normal/264.jpg  \n",
            "  inflating: /content/dataset/normal/265.jpg  \n",
            "  inflating: /content/dataset/normal/266.jpg  \n",
            "  inflating: /content/dataset/normal/267.jpg  \n",
            "  inflating: /content/dataset/normal/268.jpg  \n",
            "  inflating: /content/dataset/normal/269.jpg  \n",
            "  inflating: /content/dataset/normal/27.jpg  \n",
            "  inflating: /content/dataset/normal/270.jpg  \n",
            "  inflating: /content/dataset/normal/271.jpg  \n",
            "  inflating: /content/dataset/normal/272.jpg  \n",
            "  inflating: /content/dataset/normal/273.jpg  \n",
            "  inflating: /content/dataset/normal/274.jpg  \n",
            "  inflating: /content/dataset/normal/275.jpg  \n",
            "  inflating: /content/dataset/normal/276.jpg  \n",
            "  inflating: /content/dataset/normal/277.jpg  \n",
            "  inflating: /content/dataset/normal/278.jpg  \n",
            "  inflating: /content/dataset/normal/279.jpg  \n",
            "  inflating: /content/dataset/normal/28.jpg  \n",
            "  inflating: /content/dataset/normal/280.jpg  \n",
            "  inflating: /content/dataset/normal/281.jpg  \n",
            "  inflating: /content/dataset/normal/282.jpg  \n",
            "  inflating: /content/dataset/normal/283.jpg  \n",
            "  inflating: /content/dataset/normal/284.jpg  \n",
            "  inflating: /content/dataset/normal/285.jpg  \n",
            "  inflating: /content/dataset/normal/286.jpg  \n",
            "  inflating: /content/dataset/normal/287.jpg  \n",
            "  inflating: /content/dataset/normal/288.jpg  \n",
            "  inflating: /content/dataset/normal/289.jpg  \n",
            "  inflating: /content/dataset/normal/29.jpg  \n",
            "  inflating: /content/dataset/normal/290.jpg  \n",
            "  inflating: /content/dataset/normal/291.jpg  \n",
            "  inflating: /content/dataset/normal/292.jpg  \n",
            "  inflating: /content/dataset/normal/293.jpg  \n",
            "  inflating: /content/dataset/normal/294.jpg  \n",
            "  inflating: /content/dataset/normal/295.jpg  \n",
            "  inflating: /content/dataset/normal/296.jpg  \n",
            "  inflating: /content/dataset/normal/297.jpg  \n",
            "  inflating: /content/dataset/normal/298.jpg  \n",
            "  inflating: /content/dataset/normal/299.jpg  \n",
            "  inflating: /content/dataset/normal/3.jpg  \n",
            "  inflating: /content/dataset/normal/30.jpg  \n",
            "  inflating: /content/dataset/normal/300.jpg  \n",
            "  inflating: /content/dataset/normal/301.jpg  \n",
            "  inflating: /content/dataset/normal/302.jpg  \n",
            "  inflating: /content/dataset/normal/303.jpg  \n",
            "  inflating: /content/dataset/normal/304.jpg  \n",
            "  inflating: /content/dataset/normal/305.jpg  \n",
            "  inflating: /content/dataset/normal/306.jpg  \n",
            "  inflating: /content/dataset/normal/307.jpg  \n",
            "  inflating: /content/dataset/normal/308.jpg  \n",
            "  inflating: /content/dataset/normal/309.jpg  \n",
            "  inflating: /content/dataset/normal/31.jpg  \n",
            "  inflating: /content/dataset/normal/310.jpg  \n",
            "  inflating: /content/dataset/normal/311.jpg  \n",
            "  inflating: /content/dataset/normal/312.jpg  \n",
            "  inflating: /content/dataset/normal/313.jpg  \n",
            "  inflating: /content/dataset/normal/314.jpg  \n",
            "  inflating: /content/dataset/normal/315.jpg  \n",
            "  inflating: /content/dataset/normal/316.jpg  \n",
            "  inflating: /content/dataset/normal/317.jpg  \n",
            "  inflating: /content/dataset/normal/318.jpg  \n",
            "  inflating: /content/dataset/normal/319.jpg  \n",
            "  inflating: /content/dataset/normal/32.jpg  \n",
            "  inflating: /content/dataset/normal/320.jpg  \n",
            "  inflating: /content/dataset/normal/321.jpg  \n",
            "  inflating: /content/dataset/normal/322.jpg  \n",
            "  inflating: /content/dataset/normal/323.jpg  \n",
            "  inflating: /content/dataset/normal/324.jpg  \n",
            "  inflating: /content/dataset/normal/325.jpg  \n",
            "  inflating: /content/dataset/normal/326.jpg  \n",
            "  inflating: /content/dataset/normal/327.jpg  \n",
            "  inflating: /content/dataset/normal/328.jpg  \n",
            "  inflating: /content/dataset/normal/329.jpg  \n",
            "  inflating: /content/dataset/normal/33.jpg  \n",
            "  inflating: /content/dataset/normal/330.jpg  \n",
            "  inflating: /content/dataset/normal/331.jpg  \n",
            "  inflating: /content/dataset/normal/332.jpg  \n",
            "  inflating: /content/dataset/normal/333.jpg  \n",
            "  inflating: /content/dataset/normal/334.jpg  \n",
            "  inflating: /content/dataset/normal/335.jpg  \n",
            "  inflating: /content/dataset/normal/336.jpg  \n",
            "  inflating: /content/dataset/normal/337.jpg  \n",
            "  inflating: /content/dataset/normal/338.jpg  \n",
            "  inflating: /content/dataset/normal/339.jpg  \n",
            "  inflating: /content/dataset/normal/34.jpg  \n",
            "  inflating: /content/dataset/normal/340.jpg  \n",
            "  inflating: /content/dataset/normal/341.jpg  \n",
            "  inflating: /content/dataset/normal/342.jpg  \n",
            "  inflating: /content/dataset/normal/343.jpg  \n",
            "  inflating: /content/dataset/normal/344.jpg  \n",
            "  inflating: /content/dataset/normal/345.jpg  \n",
            "  inflating: /content/dataset/normal/346.jpg  \n",
            "  inflating: /content/dataset/normal/347.jpg  \n",
            "  inflating: /content/dataset/normal/348.jpg  \n",
            "  inflating: /content/dataset/normal/349.jpg  \n",
            "  inflating: /content/dataset/normal/35.jpg  \n",
            "  inflating: /content/dataset/normal/350.jpg  \n",
            "  inflating: /content/dataset/normal/351.jpg  \n",
            "  inflating: /content/dataset/normal/352.jpg  \n",
            "  inflating: /content/dataset/normal/36.jpg  \n",
            "  inflating: /content/dataset/normal/37.jpg  \n",
            "  inflating: /content/dataset/normal/38.jpg  \n",
            "  inflating: /content/dataset/normal/39.jpg  \n",
            "  inflating: /content/dataset/normal/4.jpg  \n",
            "  inflating: /content/dataset/normal/40.jpg  \n",
            "  inflating: /content/dataset/normal/41.jpg  \n",
            "  inflating: /content/dataset/normal/42.jpg  \n",
            "  inflating: /content/dataset/normal/43.jpg  \n",
            "  inflating: /content/dataset/normal/44.jpg  \n",
            "  inflating: /content/dataset/normal/45.jpg  \n",
            "  inflating: /content/dataset/normal/46.jpg  \n",
            "  inflating: /content/dataset/normal/47.jpg  \n",
            "  inflating: /content/dataset/normal/48.jpg  \n",
            "  inflating: /content/dataset/normal/49.jpg  \n",
            "  inflating: /content/dataset/normal/5.jpg  \n",
            "  inflating: /content/dataset/normal/50.jpg  \n",
            "  inflating: /content/dataset/normal/51.jpg  \n",
            "  inflating: /content/dataset/normal/52.jpg  \n",
            "  inflating: /content/dataset/normal/53.jpg  \n",
            "  inflating: /content/dataset/normal/54.jpg  \n",
            "  inflating: /content/dataset/normal/55.jpg  \n",
            "  inflating: /content/dataset/normal/56.jpg  \n",
            "  inflating: /content/dataset/normal/57.jpg  \n",
            "  inflating: /content/dataset/normal/58.jpg  \n",
            "  inflating: /content/dataset/normal/59.jpg  \n",
            "  inflating: /content/dataset/normal/6.jpg  \n",
            "  inflating: /content/dataset/normal/60.jpg  \n",
            "  inflating: /content/dataset/normal/61.jpg  \n",
            "  inflating: /content/dataset/normal/62.jpg  \n",
            "  inflating: /content/dataset/normal/63.jpg  \n",
            "  inflating: /content/dataset/normal/64.jpg  \n",
            "  inflating: /content/dataset/normal/65.jpg  \n",
            "  inflating: /content/dataset/normal/66.jpg  \n",
            "  inflating: /content/dataset/normal/67.jpg  \n",
            "  inflating: /content/dataset/normal/68.jpg  \n",
            "  inflating: /content/dataset/normal/69.jpg  \n",
            "  inflating: /content/dataset/normal/7.jpg  \n",
            "  inflating: /content/dataset/normal/70.jpg  \n",
            "  inflating: /content/dataset/normal/71.jpg  \n",
            "  inflating: /content/dataset/normal/72.jpg  \n",
            "  inflating: /content/dataset/normal/73.jpg  \n",
            "  inflating: /content/dataset/normal/74.jpg  \n",
            "  inflating: /content/dataset/normal/75.jpg  \n",
            "  inflating: /content/dataset/normal/76.jpg  \n",
            "  inflating: /content/dataset/normal/77.jpg  \n",
            "  inflating: /content/dataset/normal/78.jpg  \n",
            "  inflating: /content/dataset/normal/79.jpg  \n",
            "  inflating: /content/dataset/normal/8.jpg  \n",
            "  inflating: /content/dataset/normal/80.jpg  \n",
            "  inflating: /content/dataset/normal/81.jpg  \n",
            "  inflating: /content/dataset/normal/82.jpg  \n",
            "  inflating: /content/dataset/normal/83.jpg  \n",
            "  inflating: /content/dataset/normal/84.jpg  \n",
            "  inflating: /content/dataset/normal/85.jpg  \n",
            "  inflating: /content/dataset/normal/86.jpg  \n",
            "  inflating: /content/dataset/normal/87.jpg  \n",
            "  inflating: /content/dataset/normal/88.jpg  \n",
            "  inflating: /content/dataset/normal/89.jpg  \n",
            "  inflating: /content/dataset/normal/9.jpg  \n",
            "  inflating: /content/dataset/normal/90.jpg  \n",
            "  inflating: /content/dataset/normal/91.jpg  \n",
            "  inflating: /content/dataset/normal/92.jpg  \n",
            "  inflating: /content/dataset/normal/93.jpg  \n",
            "  inflating: /content/dataset/normal/94.jpg  \n",
            "  inflating: /content/dataset/normal/95.jpg  \n",
            "  inflating: /content/dataset/normal/96.jpg  \n",
            "  inflating: /content/dataset/normal/97.jpg  \n",
            "  inflating: /content/dataset/normal/98.jpg  \n",
            "  inflating: /content/dataset/normal/99.jpg  \n",
            "  inflating: /content/dataset/potholes/1.jpg  \n",
            "  inflating: /content/dataset/potholes/10.jpg  \n",
            "  inflating: /content/dataset/potholes/100.jpg  \n",
            "  inflating: /content/dataset/potholes/101.jpg  \n",
            "  inflating: /content/dataset/potholes/102.jpg  \n",
            "  inflating: /content/dataset/potholes/103.jpg  \n",
            "  inflating: /content/dataset/potholes/104.jpg  \n",
            "  inflating: /content/dataset/potholes/105.jpg  \n",
            "  inflating: /content/dataset/potholes/106.jpg  \n",
            "  inflating: /content/dataset/potholes/107.jpg  \n",
            "  inflating: /content/dataset/potholes/108.jpg  \n",
            "  inflating: /content/dataset/potholes/109.jpg  \n",
            "  inflating: /content/dataset/potholes/11.jpg  \n",
            "  inflating: /content/dataset/potholes/110.jpg  \n",
            "  inflating: /content/dataset/potholes/111.jpg  \n",
            "  inflating: /content/dataset/potholes/112.jpg  \n",
            "  inflating: /content/dataset/potholes/113.jpg  \n",
            "  inflating: /content/dataset/potholes/114.jpg  \n",
            "  inflating: /content/dataset/potholes/115.jpg  \n",
            "  inflating: /content/dataset/potholes/116.jpg  \n",
            "  inflating: /content/dataset/potholes/117.jpg  \n",
            "  inflating: /content/dataset/potholes/118.jpg  \n",
            "  inflating: /content/dataset/potholes/119.jpg  \n",
            "  inflating: /content/dataset/potholes/12.jpg  \n",
            "  inflating: /content/dataset/potholes/120.jpg  \n",
            "  inflating: /content/dataset/potholes/121.jpg  \n",
            "  inflating: /content/dataset/potholes/122.jpg  \n",
            "  inflating: /content/dataset/potholes/123.jpg  \n",
            "  inflating: /content/dataset/potholes/124.jpg  \n",
            "  inflating: /content/dataset/potholes/125.jpg  \n",
            "  inflating: /content/dataset/potholes/126.jpg  \n",
            "  inflating: /content/dataset/potholes/127.jpg  \n",
            "  inflating: /content/dataset/potholes/128.jpg  \n",
            "  inflating: /content/dataset/potholes/129.jpg  \n",
            "  inflating: /content/dataset/potholes/13.jpg  \n",
            "  inflating: /content/dataset/potholes/130.jpg  \n",
            "  inflating: /content/dataset/potholes/131.jpg  \n",
            "  inflating: /content/dataset/potholes/132.jpg  \n",
            "  inflating: /content/dataset/potholes/133.jpg  \n",
            "  inflating: /content/dataset/potholes/134.jpg  \n",
            "  inflating: /content/dataset/potholes/135.jpg  \n",
            "  inflating: /content/dataset/potholes/136.jpg  \n",
            "  inflating: /content/dataset/potholes/137.jpg  \n",
            "  inflating: /content/dataset/potholes/138.jpg  \n",
            "  inflating: /content/dataset/potholes/139.jpg  \n",
            "  inflating: /content/dataset/potholes/14.jpg  \n",
            "  inflating: /content/dataset/potholes/140.jpg  \n",
            "  inflating: /content/dataset/potholes/141.jpg  \n",
            "  inflating: /content/dataset/potholes/142.jpg  \n",
            "  inflating: /content/dataset/potholes/143.jpg  \n",
            "  inflating: /content/dataset/potholes/144.jpg  \n",
            "  inflating: /content/dataset/potholes/145.jpg  \n",
            "  inflating: /content/dataset/potholes/146.jpg  \n",
            "  inflating: /content/dataset/potholes/147.jpg  \n",
            "  inflating: /content/dataset/potholes/148.jpg  \n",
            "  inflating: /content/dataset/potholes/149.jpg  \n",
            "  inflating: /content/dataset/potholes/15.jpg  \n",
            "  inflating: /content/dataset/potholes/150.jpg  \n",
            "  inflating: /content/dataset/potholes/151.jpg  \n",
            "  inflating: /content/dataset/potholes/152.jpg  \n",
            "  inflating: /content/dataset/potholes/153.jpg  \n",
            "  inflating: /content/dataset/potholes/154.jpg  \n",
            "  inflating: /content/dataset/potholes/155.jpg  \n",
            "  inflating: /content/dataset/potholes/156.jpg  \n",
            "  inflating: /content/dataset/potholes/157.jpg  \n",
            "  inflating: /content/dataset/potholes/158.jpg  \n",
            "  inflating: /content/dataset/potholes/159.jpg  \n",
            "  inflating: /content/dataset/potholes/16.jpg  \n",
            "  inflating: /content/dataset/potholes/160.jpg  \n",
            "  inflating: /content/dataset/potholes/161.jpg  \n",
            "  inflating: /content/dataset/potholes/162.jpg  \n",
            "  inflating: /content/dataset/potholes/163.jpg  \n",
            "  inflating: /content/dataset/potholes/164.jpg  \n",
            "  inflating: /content/dataset/potholes/165.jpg  \n",
            "  inflating: /content/dataset/potholes/166.jpg  \n",
            "  inflating: /content/dataset/potholes/167.jpg  \n",
            "  inflating: /content/dataset/potholes/168.jpg  \n",
            "  inflating: /content/dataset/potholes/169.jpg  \n",
            "  inflating: /content/dataset/potholes/17.jpg  \n",
            "  inflating: /content/dataset/potholes/170.jpg  \n",
            "  inflating: /content/dataset/potholes/171.jpg  \n",
            "  inflating: /content/dataset/potholes/172.jpg  \n",
            "  inflating: /content/dataset/potholes/173.jpg  \n",
            "  inflating: /content/dataset/potholes/174.jpg  \n",
            "  inflating: /content/dataset/potholes/175.jpg  \n",
            "  inflating: /content/dataset/potholes/176.jpg  \n",
            "  inflating: /content/dataset/potholes/177.jpg  \n",
            "  inflating: /content/dataset/potholes/178.jpg  \n",
            "  inflating: /content/dataset/potholes/179.jpg  \n",
            "  inflating: /content/dataset/potholes/18.jpg  \n",
            "  inflating: /content/dataset/potholes/180.jpg  \n",
            "  inflating: /content/dataset/potholes/181.jpg  \n",
            "  inflating: /content/dataset/potholes/182.jpg  \n",
            "  inflating: /content/dataset/potholes/183.jpg  \n",
            "  inflating: /content/dataset/potholes/184.jpg  \n",
            "  inflating: /content/dataset/potholes/185.jpg  \n",
            "  inflating: /content/dataset/potholes/186.jpg  \n",
            "  inflating: /content/dataset/potholes/187.jpg  \n",
            "  inflating: /content/dataset/potholes/188.jpg  \n",
            "  inflating: /content/dataset/potholes/189.jpg  \n",
            "  inflating: /content/dataset/potholes/19.jpg  \n",
            "  inflating: /content/dataset/potholes/190.jpg  \n",
            "  inflating: /content/dataset/potholes/191.jpg  \n",
            "  inflating: /content/dataset/potholes/192.jpg  \n",
            "  inflating: /content/dataset/potholes/193.jpg  \n",
            "  inflating: /content/dataset/potholes/194.jpg  \n",
            "  inflating: /content/dataset/potholes/195.jpg  \n",
            "  inflating: /content/dataset/potholes/196.jpg  \n",
            "  inflating: /content/dataset/potholes/197.jpg  \n",
            "  inflating: /content/dataset/potholes/198.jpg  \n",
            "  inflating: /content/dataset/potholes/199.jpg  \n",
            "  inflating: /content/dataset/potholes/2.jpg  \n",
            "  inflating: /content/dataset/potholes/20.jpg  \n",
            "  inflating: /content/dataset/potholes/200.jpg  \n",
            "  inflating: /content/dataset/potholes/201.jpg  \n",
            "  inflating: /content/dataset/potholes/202.jpg  \n",
            "  inflating: /content/dataset/potholes/203.jpg  \n",
            "  inflating: /content/dataset/potholes/204.jpg  \n",
            "  inflating: /content/dataset/potholes/205.jpg  \n",
            "  inflating: /content/dataset/potholes/206.jpg  \n",
            "  inflating: /content/dataset/potholes/207.jpg  \n",
            "  inflating: /content/dataset/potholes/208.jpg  \n",
            "  inflating: /content/dataset/potholes/209.jpg  \n",
            "  inflating: /content/dataset/potholes/21.jpg  \n",
            "  inflating: /content/dataset/potholes/210.jpg  \n",
            "  inflating: /content/dataset/potholes/211.jpg  \n",
            "  inflating: /content/dataset/potholes/212.jpg  \n",
            "  inflating: /content/dataset/potholes/213.jpg  \n",
            "  inflating: /content/dataset/potholes/214.jpg  \n",
            "  inflating: /content/dataset/potholes/215.jpg  \n",
            "  inflating: /content/dataset/potholes/216.jpg  \n",
            "  inflating: /content/dataset/potholes/217.jpg  \n",
            "  inflating: /content/dataset/potholes/218.jpg  \n",
            "  inflating: /content/dataset/potholes/219.jpg  \n",
            "  inflating: /content/dataset/potholes/22.jpg  \n",
            "  inflating: /content/dataset/potholes/220.jpg  \n",
            "  inflating: /content/dataset/potholes/221.jpg  \n",
            "  inflating: /content/dataset/potholes/222.jpg  \n",
            "  inflating: /content/dataset/potholes/223.jpg  \n",
            "  inflating: /content/dataset/potholes/224.jpg  \n",
            "  inflating: /content/dataset/potholes/225.jpg  \n",
            "  inflating: /content/dataset/potholes/226.jpg  \n",
            "  inflating: /content/dataset/potholes/227.jpg  \n",
            "  inflating: /content/dataset/potholes/228.jpg  \n",
            "  inflating: /content/dataset/potholes/229.jpg  \n",
            "  inflating: /content/dataset/potholes/23.jpg  \n",
            "  inflating: /content/dataset/potholes/230.jpg  \n",
            "  inflating: /content/dataset/potholes/231.jpg  \n",
            "  inflating: /content/dataset/potholes/232.jpg  \n",
            "  inflating: /content/dataset/potholes/233.jpg  \n",
            "  inflating: /content/dataset/potholes/234.jpg  \n",
            "  inflating: /content/dataset/potholes/235.jpg  \n",
            "  inflating: /content/dataset/potholes/236.jpg  \n",
            "  inflating: /content/dataset/potholes/237.jpg  \n",
            "  inflating: /content/dataset/potholes/238.jpg  \n",
            "  inflating: /content/dataset/potholes/239.jpg  \n",
            "  inflating: /content/dataset/potholes/24.jpg  \n",
            "  inflating: /content/dataset/potholes/240.jpg  \n",
            "  inflating: /content/dataset/potholes/241.jpg  \n",
            "  inflating: /content/dataset/potholes/242.jpg  \n",
            "  inflating: /content/dataset/potholes/243.jpg  \n",
            "  inflating: /content/dataset/potholes/244.jpg  \n",
            "  inflating: /content/dataset/potholes/245.jpg  \n",
            "  inflating: /content/dataset/potholes/246.jpg  \n",
            "  inflating: /content/dataset/potholes/247.jpg  \n",
            "  inflating: /content/dataset/potholes/248.jpg  \n",
            "  inflating: /content/dataset/potholes/249.jpg  \n",
            "  inflating: /content/dataset/potholes/25.jpg  \n",
            "  inflating: /content/dataset/potholes/250.jpg  \n",
            "  inflating: /content/dataset/potholes/251.jpg  \n",
            "  inflating: /content/dataset/potholes/252.jpg  \n",
            "  inflating: /content/dataset/potholes/253.jpg  \n",
            "  inflating: /content/dataset/potholes/254.jpg  \n",
            "  inflating: /content/dataset/potholes/255.jpg  \n",
            "  inflating: /content/dataset/potholes/256.jpg  \n",
            "  inflating: /content/dataset/potholes/257.jpg  \n",
            "  inflating: /content/dataset/potholes/258.jpg  \n",
            "  inflating: /content/dataset/potholes/259.jpg  \n",
            "  inflating: /content/dataset/potholes/26.jpg  \n",
            "  inflating: /content/dataset/potholes/260.jpg  \n",
            "  inflating: /content/dataset/potholes/261.jpg  \n",
            "  inflating: /content/dataset/potholes/262.jpg  \n",
            "  inflating: /content/dataset/potholes/263.jpg  \n",
            "  inflating: /content/dataset/potholes/264.jpg  \n",
            "  inflating: /content/dataset/potholes/265.jpg  \n",
            "  inflating: /content/dataset/potholes/266.jpg  \n",
            "  inflating: /content/dataset/potholes/267.jpg  \n",
            "  inflating: /content/dataset/potholes/268.jpg  \n",
            "  inflating: /content/dataset/potholes/269.jpg  \n",
            "  inflating: /content/dataset/potholes/27.jpg  \n",
            "  inflating: /content/dataset/potholes/270.jpg  \n",
            "  inflating: /content/dataset/potholes/271.jpg  \n",
            "  inflating: /content/dataset/potholes/272.jpg  \n",
            "  inflating: /content/dataset/potholes/273.jpg  \n",
            "  inflating: /content/dataset/potholes/274.jpg  \n",
            "  inflating: /content/dataset/potholes/275.jpg  \n",
            "  inflating: /content/dataset/potholes/276.jpg  \n",
            "  inflating: /content/dataset/potholes/277.jpg  \n",
            "  inflating: /content/dataset/potholes/278.jpg  \n",
            "  inflating: /content/dataset/potholes/279.jpg  \n",
            "  inflating: /content/dataset/potholes/28.jpg  \n",
            "  inflating: /content/dataset/potholes/280.jpg  \n",
            "  inflating: /content/dataset/potholes/281.jpg  \n",
            "  inflating: /content/dataset/potholes/282.jpg  \n",
            "  inflating: /content/dataset/potholes/283.jpg  \n",
            "  inflating: /content/dataset/potholes/284.jpg  \n",
            "  inflating: /content/dataset/potholes/285.jpg  \n",
            "  inflating: /content/dataset/potholes/286.jpg  \n",
            "  inflating: /content/dataset/potholes/287.jpg  \n",
            "  inflating: /content/dataset/potholes/288.jpg  \n",
            "  inflating: /content/dataset/potholes/289.jpg  \n",
            "  inflating: /content/dataset/potholes/29.jpg  \n",
            "  inflating: /content/dataset/potholes/290.jpg  \n",
            "  inflating: /content/dataset/potholes/291.jpg  \n",
            "  inflating: /content/dataset/potholes/292.jpg  \n",
            "  inflating: /content/dataset/potholes/293.jpg  \n",
            "  inflating: /content/dataset/potholes/294.jpg  \n",
            "  inflating: /content/dataset/potholes/295.jpg  \n",
            "  inflating: /content/dataset/potholes/296.jpg  \n",
            "  inflating: /content/dataset/potholes/297.jpg  \n",
            "  inflating: /content/dataset/potholes/298.jpg  \n",
            "  inflating: /content/dataset/potholes/299.jpg  \n",
            "  inflating: /content/dataset/potholes/3.jpg  \n",
            "  inflating: /content/dataset/potholes/30.jpg  \n",
            "  inflating: /content/dataset/potholes/300.jpg  \n",
            "  inflating: /content/dataset/potholes/301.jpg  \n",
            "  inflating: /content/dataset/potholes/302.jpg  \n",
            "  inflating: /content/dataset/potholes/303.jpg  \n",
            "  inflating: /content/dataset/potholes/304.jpg  \n",
            "  inflating: /content/dataset/potholes/305.jpg  \n",
            "  inflating: /content/dataset/potholes/306.jpg  \n",
            "  inflating: /content/dataset/potholes/307.jpg  \n",
            "  inflating: /content/dataset/potholes/308.jpg  \n",
            "  inflating: /content/dataset/potholes/309.jpg  \n",
            "  inflating: /content/dataset/potholes/31.jpg  \n",
            "  inflating: /content/dataset/potholes/310.jpg  \n",
            "  inflating: /content/dataset/potholes/311.jpg  \n",
            "  inflating: /content/dataset/potholes/312.jpg  \n",
            "  inflating: /content/dataset/potholes/313.jpg  \n",
            "  inflating: /content/dataset/potholes/314.jpg  \n",
            "  inflating: /content/dataset/potholes/315.jpg  \n",
            "  inflating: /content/dataset/potholes/316.jpg  \n",
            "  inflating: /content/dataset/potholes/317.jpg  \n",
            "  inflating: /content/dataset/potholes/318.jpg  \n",
            "  inflating: /content/dataset/potholes/319.jpg  \n",
            "  inflating: /content/dataset/potholes/32.jpg  \n",
            "  inflating: /content/dataset/potholes/320.jpg  \n",
            "  inflating: /content/dataset/potholes/321.jpg  \n",
            "  inflating: /content/dataset/potholes/322.jpg  \n",
            "  inflating: /content/dataset/potholes/323.jpg  \n",
            "  inflating: /content/dataset/potholes/324.jpg  \n",
            "  inflating: /content/dataset/potholes/325.jpg  \n",
            "  inflating: /content/dataset/potholes/326.jpg  \n",
            "  inflating: /content/dataset/potholes/327.jpg  \n",
            "  inflating: /content/dataset/potholes/328.jpg  \n",
            "  inflating: /content/dataset/potholes/329.jpg  \n",
            "  inflating: /content/dataset/potholes/33.jpg  \n",
            "  inflating: /content/dataset/potholes/34.jpg  \n",
            "  inflating: /content/dataset/potholes/35.jpg  \n",
            "  inflating: /content/dataset/potholes/36.jpg  \n",
            "  inflating: /content/dataset/potholes/37.jpg  \n",
            "  inflating: /content/dataset/potholes/38.jpg  \n",
            "  inflating: /content/dataset/potholes/39.jpg  \n",
            "  inflating: /content/dataset/potholes/4.jpg  \n",
            "  inflating: /content/dataset/potholes/40.jpg  \n",
            "  inflating: /content/dataset/potholes/41.jpg  \n",
            "  inflating: /content/dataset/potholes/42.jpg  \n",
            "  inflating: /content/dataset/potholes/43.jpg  \n",
            "  inflating: /content/dataset/potholes/44.jpg  \n",
            "  inflating: /content/dataset/potholes/45.jpg  \n",
            "  inflating: /content/dataset/potholes/46.jpg  \n",
            "  inflating: /content/dataset/potholes/47.jpg  \n",
            "  inflating: /content/dataset/potholes/48.jpg  \n",
            "  inflating: /content/dataset/potholes/49.jpg  \n",
            "  inflating: /content/dataset/potholes/5.jpg  \n",
            "  inflating: /content/dataset/potholes/50.jpg  \n",
            "  inflating: /content/dataset/potholes/51.jpg  \n",
            "  inflating: /content/dataset/potholes/52.jpg  \n",
            "  inflating: /content/dataset/potholes/53.jpg  \n",
            "  inflating: /content/dataset/potholes/54.jpg  \n",
            "  inflating: /content/dataset/potholes/55.jpg  \n",
            "  inflating: /content/dataset/potholes/56.jpg  \n",
            "  inflating: /content/dataset/potholes/57.jpg  \n",
            "  inflating: /content/dataset/potholes/58.jpg  \n",
            "  inflating: /content/dataset/potholes/59.jpg  \n",
            "  inflating: /content/dataset/potholes/6.jpg  \n",
            "  inflating: /content/dataset/potholes/60.jpg  \n",
            "  inflating: /content/dataset/potholes/61.jpg  \n",
            "  inflating: /content/dataset/potholes/62.jpg  \n",
            "  inflating: /content/dataset/potholes/63.jpg  \n",
            "  inflating: /content/dataset/potholes/64.jpg  \n",
            "  inflating: /content/dataset/potholes/65.jpg  \n",
            "  inflating: /content/dataset/potholes/66.jpg  \n",
            "  inflating: /content/dataset/potholes/67.jpg  \n",
            "  inflating: /content/dataset/potholes/68.jpg  \n",
            "  inflating: /content/dataset/potholes/69.jpg  \n",
            "  inflating: /content/dataset/potholes/7.jpg  \n",
            "  inflating: /content/dataset/potholes/70.jpg  \n",
            "  inflating: /content/dataset/potholes/71.jpg  \n",
            "  inflating: /content/dataset/potholes/72.jpg  \n",
            "  inflating: /content/dataset/potholes/73.jpg  \n",
            "  inflating: /content/dataset/potholes/74.jpg  \n",
            "  inflating: /content/dataset/potholes/75.jpg  \n",
            "  inflating: /content/dataset/potholes/76.jpg  \n",
            "  inflating: /content/dataset/potholes/77.jpg  \n",
            "  inflating: /content/dataset/potholes/78.jpg  \n",
            "  inflating: /content/dataset/potholes/79.jpg  \n",
            "  inflating: /content/dataset/potholes/8.jpg  \n",
            "  inflating: /content/dataset/potholes/80.jpg  \n",
            "  inflating: /content/dataset/potholes/81.jpg  \n",
            "  inflating: /content/dataset/potholes/82.jpg  \n",
            "  inflating: /content/dataset/potholes/83.jpg  \n",
            "  inflating: /content/dataset/potholes/84.jpg  \n",
            "  inflating: /content/dataset/potholes/85.jpg  \n",
            "  inflating: /content/dataset/potholes/86.jpg  \n",
            "  inflating: /content/dataset/potholes/87.jpg  \n",
            "  inflating: /content/dataset/potholes/88.jpg  \n",
            "  inflating: /content/dataset/potholes/89.jpg  \n",
            "  inflating: /content/dataset/potholes/9.jpg  \n",
            "  inflating: /content/dataset/potholes/90.jpg  \n",
            "  inflating: /content/dataset/potholes/91.jpg  \n",
            "  inflating: /content/dataset/potholes/92.jpg  \n",
            "  inflating: /content/dataset/potholes/93.jpg  \n",
            "  inflating: /content/dataset/potholes/94.jpg  \n",
            "  inflating: /content/dataset/potholes/95.jpg  \n",
            "  inflating: /content/dataset/potholes/96.jpg  \n",
            "  inflating: /content/dataset/potholes/97.jpg  \n",
            "  inflating: /content/dataset/potholes/98.jpg  \n",
            "  inflating: /content/dataset/potholes/99.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCbM9HV5Zj7z",
        "outputId": "76aff689-3faf-4b73-8826-867588b9de08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.10/dist-packages (2.7.14)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai) (24.0)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.29)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.17.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai) (2.31.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai) (6.0.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai) (9.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai) (1.11.4)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.4)\n",
            "Requirement already satisfied: torch<2.3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from fastai) (2.2.1+cu121)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (4.66.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m858.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=1.10->fastai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4->fastai) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3,>=1.10->fastai) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "from fastai.data.all import *"
      ],
      "metadata": {
        "id": "Gcc4RN_XZnM-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zBUUHTeYySY",
        "outputId": "491d9918-30da-43b1-e8fc-5ec270ac8759"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare your image(s) here\n",
        "path = Path('/content/dataset')\n",
        "print(path.ls())\n",
        "\n",
        "\n",
        "print(get_image_files(path/\"normal\")[:5])\n",
        "\n",
        "potholes = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=Resize(460),\n",
        "    batch_tfms=aug_transforms(size=224, min_scale=0.75)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJql5gWQXL5U",
        "outputId": "83e56ddd-bebd-43b0-9000-b10c8d9e302d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Path('/content/dataset/potholes'), Path('/content/dataset/normal')]\n",
            "[Path('/content/dataset/normal/82.jpg'), Path('/content/dataset/normal/325.jpg'), Path('/content/dataset/normal/309.jpg'), Path('/content/dataset/normal/8.jpg'), Path('/content/dataset/normal/49.jpg')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('/content/dataset/normal/100.jpg', target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "predictions = model.predict(x)\n",
        "\n",
        "print('Predicted:', decode_predictions(predictions, top=3)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dijXBmlAaVhR",
        "outputId": "e8458c46-2e48-4516-b197-86c59587bbbb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 339ms/step\n",
            "Predicted: [('n06794110', 'street_sign', 0.5741842), ('n03000134', 'chainlink_fence', 0.04941808), ('n02835271', 'bicycle-built-for-two', 0.035230584)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning a pretrained backbone"
      ],
      "metadata": {
        "id": "FuJjn9xUbk4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Pre-Trained Model"
      ],
      "metadata": {
        "id": "9r_lX9AYbp9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6FwF65TboJx",
        "outputId": "ee94c13f-de21-4afd-df87-f898f04730d5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "vDaQed3SbsSA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "j6BoohNcb196"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "Q7PgcvBCccp_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n"
      ],
      "metadata": {
        "id": "vIxNTbLacdbO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/dataset'\n",
        "batch_size = 16\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')  # Use 'binary' for binary classification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt-ZREuBce3b",
        "outputId": "bdd0cff8-7df9-42e3-8064-d8702160d21c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 681 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "epochs = 1\n"
      ],
      "metadata": {
        "id": "a-5Rw61Kc3-Y"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "VEfOibQRdQyB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data_dir = '/content/dataset'\n",
        "validation_batch_size = 16\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=validation_batch_size,\n",
        "    class_mode='binary')  # Use 'binary' for binary classification if you have two classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuSc0fqzdRqu",
        "outputId": "935f9646-dc96-4923-efcd-6a5ec06a9f36"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 681 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_steps = validation_generator.samples // validation_generator.batch_size\n"
      ],
      "metadata": {
        "id": "R76KpVvhduok"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Add new layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # This is an example; adjust as per your last layer\n",
        "x = Dense(1024, activation='relu')(x)  # A dense layer as before\n",
        "new_output = Dense(1, activation='sigmoid')(x)  # New binary classification output layer\n",
        "\n",
        "# Define the new model\n",
        "new_model = Model(inputs=base_model.input, outputs=new_output)\n",
        "\n",
        "# Compile the new model\n",
        "new_model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "sFslFQeJeffD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = new_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "WaIr0oWhdYG6",
        "outputId": "a10ff672-2c05-4967-8ec0-886a0351be3c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - ETA: 0s - loss: 0.7860 - accuracy: 0.5158"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-1f74694b914a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = new_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1854\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m                         )\n\u001b[0;32m-> 1856\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1857\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2294\u001b[0m                         ):\n\u001b[1;32m   2295\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2296\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2297\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a image classifier from scratch"
      ],
      "metadata": {
        "id": "jP7P_8FwjCWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "Dod4UiAKjC-C"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Use 'softmax' if you have more than 2 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # Change to 'categorical_crossentropy' if you have more than 2 classes\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "vuhwjhLsjFR9"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale for validation data\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/dataset',  # This is the target directory\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        class_mode='binary')  # Use 'binary' for binary classification, 'categorical' for multi-class\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/dataset',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')  # Use 'binary' for binary classification, 'categorical' for multi-class\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIb7JBa7jLO0",
        "outputId": "d2f27f8a-0c40-49f8-926d-6d67e3a74725"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 681 images belonging to 2 classes.\n",
            "Found 681 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=30,  # Number of images = batch_size * steps\n",
        "      epochs=1,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=25,  # Number of images = batch_size * steps\n",
        "      verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj1wjn66jX9g",
        "outputId": "04e71468-a90f-4717-caef-649c3e1a93a1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 25 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 - 74s - loss: 0.8837 - accuracy: 0.5551 - val_loss: 0.6623 - val_accuracy: 0.5213 - 74s/epoch - 2s/step\n"
          ]
        }
      ]
    }
  ]
}